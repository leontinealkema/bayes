---
title: "Applied Bayesian Modeling - modules 7 and 8"
author: "Leontine Alkema"
date: "September 25, 2022"
output: 
  pdf_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(brms)
library(tidybayes) # added mostly as a reference for future use, for easier manipulation of posterior samples. 
# used here for function `point_interval'
```

# Read in radon data 
Read in the radon data and process (copied from earlier module)
```{r}
# house level data
d <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/srrs2.dat"), 
                header=T, sep=",")

# deal with zeros, select what we want, make a fips (county) variable to match on 
d <- d %>% 
  mutate(activity = ifelse(activity==0, 0.1, activity)) %>% 
  mutate(fips = stfips * 1000 + cntyfips) %>%   
  dplyr::select(fips, state, county, floor, activity)

# county level data
cty <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/cty.dat"), 
                  header = T, sep = ",")
cty <- 
  cty %>% 
  mutate(fips = 1000 * stfips + ctfips) %>% 
  dplyr::select(fips, Uppm) %>%
  rename(ura_county = (Uppm))

dmn <- d %>% 
  filter(state=="MN") %>% # Minnesota data only
  dplyr::select(fips, county, floor, activity) %>% 
  left_join(cty) 

```



## More data processing for multilevel modeling

Some more data processing first, to produce a data set that has county info and to produce the plot with means from the slides. In the data set:

- $y_i$ is log(activity)
- county gives county name (fips gives the unique county ID)
- $x_i$ is floor
- $u_i$ is log_ur = log(ura_county)

(the last two are added for module 8, when including predictors)

```{r}
dat <- 
  dmn%>%
  mutate(y = log(activity), log_ur = log(ura_county))
head(dat)
```

Create summary data set with info for each county:
```{r}
# to plot observations and county means ~ sample sizes, 
# easier to see if sample sizes are slighly jittered
set.seed(12345)

datcounty <- dat %>%
  group_by(fips) %>%
  summarize(nhouses = n(), ybar = mean(y), county = county[1], log_ur = log_ur[1]) %>%
  mutate(nhouses_jitter = nhouses*exp(runif (length(nhouses), -.1, .1)))
ngroups <- dim(datcounty)[1]
head(datcounty)
```


```{r}
ybarbar <- mean(dat$y) # population (here state) mean
```

```{r}
datcounty %>% 
  ggplot(aes(x = nhouses_jitter, y = ybar)) +
  geom_point() + 
  geom_hline(mapping = aes(yintercept = ybarbar)) + 
  theme_bw()
```

# Model fitting w/o predictors

```{r}
fit <- brm(y ~ (1|county), 
        data = dat, 
        iter = 1000,
        chains = 4,
        cores = getOption("mc.cores", 4))
```

Summary of model fit: 
```{r}
summary(fit)
```

## Visualizing the group-level mean parameters 

Coefficients can be obtained using coef(fit), you can get the help file here:
```{r}
#?coef.brmsfit 
```

Just showing some function calls here first, ie for  mu_alpha:
```{r}
fixef(fit)
```


eta = alpha - mu_alpha (as compared to notation in slides), labeled here as random effects 
```{r}
eta <- as_tibble(ranef(fit)$county[,,"Intercept"], rownames = "county")
head(eta)
```

To get the alpha = eta + mu_alpha, we can use the following call
```{r}
alphas <-
  coef(fit, summary = T)$county %>% 
  as_tibble(rownames = "county") %>%
  rename(alph = Estimate.Intercept)
alphas 
```

Make the plot of alpha ~ ybar
```{r}
alphas %>%
  left_join(datcounty) %>%
  ggplot(aes(y = alph, x = ybar, size = nhouses)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0)
```

Plot of alpha - ybar
```{r}
alphas %>%
  left_join(datcounty) %>%
  ggplot(aes(y = alph - ybar, x = nhouses)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

## Predicting radon levels in unsampled houses and unsampled counties


### Do-it-yourself sampling based approach

We first obtain posterior samples of the hyperparameters and then sample from the predictive distribution for our outcomes of interest, e.g. new observations or group means for new groups.

Extract the posterior samples from the brm-fit: 
```{r}
samp <- as_draws_df(fit)
#dim(samp)
#names(samp)[1:3]
sigmay_s <- samp$sigma
mualpha_s <- samp$b_Intercept
sigmaalpha_s <- samp$sd_county__Intercept
S <- length(sigmay_s)
county_names <- rownames(ranef(fit)$county)
```

Sampling for a new observation, for example from 1st county Aitkin: 
```{r}
county_names[1] # just note there are spaces in names, so little more annoying to work with
alpha1_s <- mualpha_s + samp$`r_county[AITKIN..............,Intercept]`

set.seed(1234) # to make the sampling reproducible
ytilde_s <- rnorm(S, alpha1_s, sigmay_s)
```


Point estimates and 95% CI (using point_interval function from tidybayes package here):
```{r}
point_interval(ytilde_s, .point = mean) 
```

Visualize densities
```{r}
p <- as_tibble(alpha1_s) %>%
  ggplot(aes(alpha1_s, after_stat(density))) +
  geom_histogram(alpha = .5, fill = "blue", bins = 60) +
  theme_minimal() +
  xlab("Log radon") +
  geom_vline(xintercept = mean(alpha1_s), col = "blue")
p +
  geom_histogram(as_tibble(ytilde_s), , bins = 30, mapping = aes(ytilde_s, after_stat(density)), 
               alpha = .5, fill = "red", adjust = 1.5, size = 1.5) +
  geom_vline(xintercept = mean(ytilde_s), col = "red", linetype = "dashed")
    

```

Sampling for a new group mean: 
```{r}
set.seed(1234) # to make the sampling reproducible
alphanew_s <- rnorm(length(sigmaalpha_s), mualpha_s, sigmaalpha_s)
```

Visualizing the densities
```{r}
p <- as_tibble(mualpha_s) %>%
  ggplot(aes(mualpha_s, after_stat(density))) +
  geom_histogram(alpha = .5, bins = 60) +
  theme_minimal() +
  xlab("Log radon") +
  geom_vline(xintercept = mean(mualpha_s))
p +
  geom_histogram(aes(alphanew_s, after_stat(density)), alpha = .5, fill = "blue", bins = 30, fill = "blue") +
  geom_vline(xintercept = mean(alphanew_s), col = "blue", linetype = "dashed")
    

```


### Can brm-functions do this for me? 

Yes, they can! And when you've fully understood what you're doing, I recommend you take this approach :)  

Prediction for a new house in county 1, we just need a data frame with the county name here (given no predictors)
```{r}
newdata1 <- data.frame(
  county = county_names[1] 
)
ytilde_brm_s <- posterior_predict(fit, newdata = newdata1)

```

Compare the two intervals, should be approximately the same
```{r}
point_interval(ytilde_s, .point = mean) 
point_interval(ytilde_brm_s, .point = mean) 
```


# Model fitting with predictors 

Add group-level predictor floor:
```{r}
fit2 <- brm(y ~ (1+floor|county) + floor,
            data = dat, sample_prior = T, chains = 4,
            iter = 2000, thin = 1,
            cores = getOption("mc.cores", 4))
```


```{r}
summary(fit2)
```

Visualize the fitted regression line (although here just two values for the covariate x, 0 and 1), for each county

```{r}
coefs <- coef(fit2)$county[, 'Estimate', c("Intercept", "floor")]

coefs_tibble <- as_tibble(rownames =  "county", coefs) %>%
  rename(slope = floor)

dat %>%
  full_join(coefs_tibble, by = "county") %>%
  filter(county %in% coefs_tibble$county[1:9]) %>% # just select 4 counties
  ggplot(aes(x = floor, y = y)) +
  geom_point() +
  geom_abline(aes(intercept = Intercept, slope = slope)) +
  geom_abline(aes(intercept = fixef(fit2)[, "Estimate"][1], 
                  slope = fixef(fit2)[, "Estimate"][2]), col = "red") +
  facet_wrap( ~ county)
```





Fit the full model, including county-level uranium 

```{r}
fit3 <- brm(y ~ (1 + floor|county) + log_ur*floor, family = gaussian(), 
            data = dat, sample_prior = T, chains = 4,
            iter = 2000, thin = 1,
            cores = getOption("mc.cores", 4))
```


```{r}
summary(fit3)
```



